{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":35332,"databundleVersionId":3723648,"sourceType":"competition"},{"sourceId":3739819,"sourceType":"datasetVersion","datasetId":2231132},{"sourceId":4017635,"sourceType":"datasetVersion","datasetId":2381088},{"sourceId":4040541,"sourceType":"datasetVersion","datasetId":2380868}],"dockerImageVersionId":30213,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!rm -rf /kaggle/working/*","metadata":{"execution":{"iopub.status.busy":"2024-09-28T05:34:26.821773Z","iopub.execute_input":"2024-09-28T05:34:26.822307Z","iopub.status.idle":"2024-09-28T05:34:29.216704Z","shell.execute_reply.started":"2024-09-28T05:34:26.822205Z","shell.execute_reply":"2024-09-28T05:34:29.214322Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import gc\nimport os\nimport joblib\nimport random\nimport warnings\nimport itertools\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport lightgbm as lgb\nfrom itertools import combinations\npd.set_option('display.width', 1000)\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\nfrom sklearn.preprocessing import LabelEncoder\nimport warnings; warnings.filterwarnings('ignore')\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\n\ndef get_difference(data, num_features):\n    df1 = []\n    customer_ids = []\n    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n        df1.append(diff_df1)\n        customer_ids.append(customer_id)\n    df1 = np.concatenate(df1, axis = 0)\n    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n    df1['customer_ID'] = customer_ids\n    return df1\n\ndef read_preprocess_data():\n    train = pd.read_parquet('../input/amex-data-integer-dtypes-parquet-format/train.parquet')\n    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n    cat_features = [\n        \"B_30\",\n        \"B_38\",\n        \"D_114\",\n        \"D_116\",\n        \"D_117\",\n        \"D_120\",\n        \"D_126\",\n        \"D_63\",\n        \"D_64\",\n        \"D_66\",\n        \"D_68\",\n    ]\n    num_features = [col for col in features if col not in cat_features]\n  \n    print('Starting training feature engineer...')\n    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n    train_num_agg.reset_index(inplace = True)\n\n    for col in train_num_agg:\n        for col_2 in ['first', 'mean']:\n            if 'last' in col and col.replace('last', col_2) in train_num_agg:\n                train_num_agg[col.replace('last', col_2) + '_last_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', col_2)]\n                train_num_agg[col.replace('last', col_2) + '_last_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', col_2)]\n\n    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'first', 'last', 'nunique'])\n    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n    train_cat_agg.reset_index(inplace = True)\n    train_labels = pd.read_csv('../input/amex-default-prediction/train_labels.csv')\n\n    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n    for col in tqdm(cols):\n        train_num_agg[col] = train_num_agg[col].astype(np.float32)\n\n    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n    for col in tqdm(cols):\n        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n\n    train_diff = get_difference(train, num_features)\n    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_diff, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n    \n    del train_num_agg, train_cat_agg, train_diff\n    cat_features_last = [f\"{cf}_last\" for cf in cat_features]\n    for cat_col in cat_features_last:\n        encoder = LabelEncoder()\n        train[cat_col] = encoder.fit_transform(train[cat_col])\n        joblib.dump(encoder, f'{cat_col}_encoder.pkl')\n\n    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n    num_cols = [col for col in num_cols if 'last' in col]\n    for col in num_cols:\n        train[col + '_round2'] = train[col].round(2)\n    train.to_parquet('train_fe_v3_loaded_rectified.parquet')\n    del train\n    gc.collect()\n    test = pd.read_parquet('../input/amex-data-integer-dtypes-parquet-format/test.parquet')\n    print('Starting test feature engineer...')\n    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n    test_num_agg.reset_index(inplace = True)\n\n   \n    for col in test_num_agg:\n        for col_2 in ['first', 'mean']:\n            if 'last' in col and col.replace('last', col_2) in test_num_agg:\n                test_num_agg[col.replace('last', col_2) + '_last_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', col_2)]\n                test_num_agg[col.replace('last', col_2) + '_last_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', col_2)]\n    \n    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'first', 'last', 'nunique'])\n    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n    test_cat_agg.reset_index(inplace = True)\n\n    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n    for col in tqdm(cols):\n        test_num_agg[col] = test_num_agg[col].astype(np.float32)\n\n    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n    for col in tqdm(cols):\n        test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n \n    test_diff = get_difference(test, num_features)\n    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID').merge(test_diff, how = 'inner', on = 'customer_ID')\n    del test_num_agg, test_cat_agg, test_diff\n    gc.collect()\n \n    cat_features_last = [f\"{cf}_last\" for cf in cat_features]\n    for cat_col in cat_features_last:\n        loaded_encoder = joblib.load(f'{cat_col}_encoder.pkl')\n        test[cat_col] = loaded_encoder.transform(test[cat_col])\n   \n    num_cols = list(test.dtypes[(test.dtypes == 'float32') | (test.dtypes == 'float64')].index)\n    num_cols = [col for col in num_cols if 'last' in col]\n    for col in num_cols:\n        test[col + '_round2'] = test[col].round(2)\n    test.to_parquet('test_fe_v3_loaded_rectified.parquet')\n    \n\nread_preprocess_data()","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":2.938351,"end_time":"2022-07-29T20:37:56.259526","exception":false,"start_time":"2022-07-29T20:37:53.321175","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2024-09-28T05:34:29.228283Z","iopub.execute_input":"2024-09-28T05:34:29.233620Z","iopub.status.idle":"2024-09-28T06:32:21.883751Z","shell.execute_reply.started":"2024-09-28T05:34:29.233510Z","shell.execute_reply":"2024-09-28T06:32:21.882084Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}},{"name":"stdout","text":"Starting training feature engineer...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 513/513 [00:28<00:00, 18.04it/s] \n100%|██████████| 22/22 [00:00<00:00, 97.48it/s]\n100%|██████████| 458913/458913 [11:51<00:00, 644.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting test feature engineer...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 513/513 [01:22<00:00,  6.20it/s] \n100%|██████████| 22/22 [00:00<00:00, 45.49it/s]\n100%|██████████| 924621/924621 [24:34<00:00, 626.87it/s]\n","output_type":"stream"}]}]}